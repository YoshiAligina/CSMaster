---
title: "R Notebook"
output: html_notebook
---


```{r}
unlink("C:/Users/yoshi/AppData/Roaming/R-3.6.3/library/00LOCK-rsample", recursive = TRUE)

#Had an issue with 00Lock problems, so I had to include the above statement. Here I am  importing libraries, 
#setting the working directory, and reading the CSV files. 
library(rpart)
library(rpart.plot)
library(dplyr)
library(rsample)
library(randomForest)
library(caret)
library(doParallel)
library(ranger)
library(ggplot2)
setwd("C:/Users/yoshi/OneDrive/Documents/Data101")

EarningsTrain <- read.csv("C:/Users/yoshi/OneDrive/Documents/Data101/EarningsTrain.csv")
Test <- read.csv("C:/Users/yoshi/OneDrive/Documents/Data101/EarningsTest.csv")
```

```{r}
#Here, I am splitting this into a 70-30 split of my training set with my favourite number. 
set.seed(777) # My fav number <3

esplit <- initial_split(EarningsTrain, prop = 0.75)
train <- training(esplit)
val <- testing(esplit)


```

```{r}
#Model training using the first part of the training dataset.


# Exclude 'pred.Earnings' from the list of column names
earn <- rpart(Earnings ~ ., data = train, method = "anova",
              control = rpart.control(cp = 0.001, minsplit = 27, minbucket = 10, maxdepth = 8))
``



train$pred.Earnings <- predict(earn, train)
MSE_train <- mean((train$Earnings - train$pred.Earnings)^2)

#Model training using the second part of the training dataset.
val$pred.Earnings <- predict(earn, val)
MSE_val <- mean((val$Earnings - val$pred.Earnings)^2)

#MSES made for the two  of them!
print(paste("MSE Training: ", MSE_train))
print(paste("MSE Validation: ", MSE_val))

#Visualising the current tree, it looks very confusing straight off the bat.
rpart.plot(earn, type=4, fallen.leaves = TRUE)
```

```{r}
# I think that this means I need to start working on making tweaks and trying new ideas to lower my MSE as much as possible.

#forest_model <- randomForest(Earnings ~ ., data = train, ntree = 10432, mtry = 4, nodesize = 5)

# Define the control for cross-validation

#Here, I created a feature with Height and Professional Connections. I feel like height is considered to be a characteristic
# that many people find to be important and it is often the first thing people see. I feel it could be height dependent. 
train$HP <- train$Height * train$Number_Of_Professional_Connections
val$HP <- val$Height * val$Number_Of_Professional_Connections
Test$HP <- Test$Height * Test$Number_Of_Professional_Connections

#And for this, I created a feature of Grad year and Credits. This is because more credits assumes an intensive degree, and during the older years, a more impressive degree may carry more weight. 
train$GC<- train$Graduation_Year * train$Number_Of_Credits
val$GC <- val$Graduation_Year * val$Number_Of_Credits
Test$GC <- Test$Graduation_Year * Test$Number_Of_Credits


train_control <- trainControl(method = "cv", number = 10, allowParallel = TRUE)

# Define the tuning grid. Note the prefix with dot (.) for ranger-specific parameters in caret
tune_grid <- expand.grid(
  .mtry = c(2,3, 4,5,6),
  .splitrule = c("variance", "extratrees"),
  .min.node.size = c(2,3,4)
)

# Train the model with the corrected tuning grid
model <- train(
  Earnings ~ .,
  data = train,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  num.trees = 700 # Specifying the number of trees directly here
)


predEarn_RF <- predict(model, val)
MSE_RF <- mean((val$Earnings - predEarn_RF)^2)
print(paste("FINAL MSE Validation with Random Forest: ", MSE_RF))


# Initially, I got an MSE of 9000, which is pretty good comparing to the prior of 100 k.Then was suggested to try some tuning methods which involved increasing the number of trees, and otherwise using cross validation methods. It suggested I use the ranger method in caret as it is more efficient than that of the RF method. From that, I got down to 7000 MSE, and now I just have to mess with the settings / tree amount to lower this below my goal of 5000 It did NOT go well, so I decided to try to create some new features and test it out. Getting down to 6700.

#However, when I was working on this, and attempting to lower my MSE, I was measuring the measure of accuracy, utilising a ggplot2 function given to me by CGPT, and the accuracy reached 100% prior to 5% margin of error, so I feel like it is best to reduce a few things and leave it at this as too low of an MSE may cause overfitting. 

```
```{r}
Test$predEarnings <- predict(model, Test)
write.csv(Test, "EarningsTest_with_PredEarnings.csv", row.names = FALSE)

```


